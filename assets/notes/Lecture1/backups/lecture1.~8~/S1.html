<!DOCTYPE html><html lang="en-GB">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>1. BAYESIAN INFERENCE â€£ Lecture 1: Foundations in Deterministic and Stochastic Optimization</title>
<!--Generated on Mon Mar 18 14:06:24 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->

<link rel="stylesheet" href="LaTeXML.css" type="text/css">
<link rel="stylesheet" href="ltx-article.css" type="text/css">
<link rel="stylesheet" href="ltx-amsart.css" type="text/css">
<link rel="stylesheet" href="bookml/gitbook/css/style.css" type="text/css">
<link rel="stylesheet" href="bookml/gitbook/css/plugin-table.css" type="text/css">
<link rel="stylesheet" href="bookml/gitbook/css/plugin-bookdown.css" type="text/css">
<link rel="stylesheet" href="bookml/gitbook/css/plugin-fontsettings.css" type="text/css">
<link rel="stylesheet" href="bookml/CSS/style.css" type="text/css">
<link rel="stylesheet" href="bookml/CSS/style.gitbook,plain.css" type="text/css">
<link rel="stylesheet" href="bookml/CSS/style.gitbook.css" type="text/css">
<link rel="stylesheet" href="bmluser/lecture1.colors.gitbook.css" type="text/css">
<link rel="stylesheet" href="bmluser/template.colors.gitbook.css" type="text/css">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<script src="https://code.jquery.com/jquery-3.6.0.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>
<link rel="up" href="index.html" title="Lecture 1: Foundations in Deterministic and Stochastic Optimization">
<link rel="start" href="index.html" title="Lecture 1: Foundations in Deterministic and Stochastic Optimization">
<link rel="prev" href="index.html" title="Lecture 1: Foundations in Deterministic and Stochastic Optimization">
<link rel="next" href="S2.html" title="2. From Inference to Learning â€£ Lecture 1: Foundations in Deterministic and Stochastic Optimization">
<link rel="section" href="S2.html" title="2. From Inference to Learning â€£ Lecture 1: Foundations in Deterministic and Stochastic Optimization">
</head>
<body>
<div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">
<a href="#bml-main-content" tabindex="0" class="bml-skip-to-content">Skip to content.</a>
<div class="book-summary"><nav class="ltx_page_navbar">
<ul class="ltx_toclist summary">
<li>
<a href="index.html" title="" class="ltx_ref" rel="start">Lecture 1: Foundations in Deterministic and Stochastic Optimization</a>
</li>
<li class="divider">
<li data-level="1" data-path="" class="ltx_tocentry ltx_tocentry_section ltx_ref_self  chapter active"><a href="" title="In Lecture 1: Foundations in Deterministic and Stochastic Optimization" class="ltx_ref"><b><span class="ltx_tag ltx_tag_ref">1 </span></b>Bayesian Inference</a></li>
<li data-level="2" data-path="S2.html" class="ltx_tocentry ltx_tocentry_section  chapter "><a href="S2.html" title="In Lecture 1: Foundations in Deterministic and Stochastic Optimization" class="ltx_ref"><b><span class="ltx_tag ltx_tag_ref">2 </span></b>From Inference to Learning</a></li>
</ul>
</nav></div>
<div class="ltx_page_main book-body fixed">
<div class="body-inner">
<div class="book-header fixed" role="navigation"><h1>BAYESIAN INFERENCE</h1></div>
<div class="page-wrapper" tabindex="-1" role="main">
<div class="ltx_page_content page-inner" id="bml-main-content">
<section class="ltx_section ltx_authors_1line ltx_leqno normal" lang="en-GB">
<div class="section level1">

<h1 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section header-section-number">1</span>. BAYESIAN INFERENCE</h1>

<div id="p1" class="ltx_para">
<p class="ltx_p">One of the most fundamental problems in statistics, signal processing, and machine learning, is the <em class="ltx_emph ltx_font_italic">inference</em> problem, where we wish to construct an estimate of some random quantity of interest <math id="p1.m1" class="ltx_Math" alttext="\boldsymbol{\gamma}\in\mathds{R}^{M_{\boldsymbol{\gamma}}}" display="inline"><semantics><mrow><mi>ğœ¸</mi><mo>âˆˆ</mo><msup><mi>â„</mi><msub><mi>M</mi><mi>ğœ¸</mi></msub></msup></mrow><annotation encoding="application/x-tex">\boldsymbol{\gamma}\in\mathds{R}^{M_{\boldsymbol{\gamma}}}</annotation></semantics></math>, given observations of a related random variable <math id="p1.m2" class="ltx_Math" alttext="\boldsymbol{h}\in\mathds{R}^{M_{\boldsymbol{h}}}" display="inline"><semantics><mrow><mi>ğ’‰</mi><mo>âˆˆ</mo><msup><mi>â„</mi><msub><mi>M</mi><mi>ğ’‰</mi></msub></msup></mrow><annotation encoding="application/x-tex">\boldsymbol{h}\in\mathds{R}^{M_{\boldsymbol{h}}}</annotation></semantics></math>. The quantity of interest <math id="p1.m3" class="ltx_Math" alttext="\boldsymbol{\gamma}" display="inline"><semantics><mi>ğœ¸</mi><annotation encoding="application/x-tex">\boldsymbol{\gamma}</annotation></semantics></math> may take on continuous or discrete values, and is referred to as the â€œdependent variable,â€ â€œstate of nature,â€ â€œclass,â€ or â€œlabelâ€ depending on the application. We will most commonly refer to it as the label. We will refer to the observed random variable <math id="p1.m4" class="ltx_Math" alttext="\boldsymbol{h}" display="inline"><semantics><mi>ğ’‰</mi><annotation encoding="application/x-tex">\boldsymbol{h}</annotation></semantics></math> generally as the feature, although in some applications it is known as â€œregressorâ€ or â€œobservationâ€.</p>
</div>
<div id="p2" class="ltx_para">
<p class="ltx_p">If we are provided with the conditional distribution <math id="p2.m1" class="ltx_Math" alttext="f_{\boldsymbol{\gamma}|\boldsymbol{h}}(\gamma|h)" display="inline"><semantics><mrow><msub><mi>f</mi><mrow><mi>ğœ¸</mi><mo fence="false">|</mo><mi>ğ’‰</mi></mrow></msub><mo>â¢</mo><mrow><mo stretchy="false">(</mo><mrow><mi>Î³</mi><mo fence="false">|</mo><mi>h</mi></mrow><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">f_{\boldsymbol{\gamma}|\boldsymbol{h}}(\gamma|h)</annotation></semantics></math> along with a single realization of the feature <math id="p2.m2" class="ltx_Math" alttext="\boldsymbol{h}" display="inline"><semantics><mi>ğ’‰</mi><annotation encoding="application/x-tex">\boldsymbol{h}</annotation></semantics></math>, it is quite natural to estimate <math id="p2.m3" class="ltx_Math" alttext="\boldsymbol{\gamma}" display="inline"><semantics><mi>ğœ¸</mi><annotation encoding="application/x-tex">\boldsymbol{\gamma}</annotation></semantics></math> as the most likely outcome given <math id="p2.m4" class="ltx_Math" alttext="\boldsymbol{h}" display="inline"><semantics><mi>ğ’‰</mi><annotation encoding="application/x-tex">\boldsymbol{h}</annotation></semantics></math>. We can express this formally as:</p>
<div style="max-width: 100%; overflow-x: auto; overflow-y: hidden;">
<table id="S2.EGx1" class="ltx_equationgroup ltx_eqn_align ltx_eqn_table">

<tbody id="E1"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left"><span class="ltx_tag ltx_tag_equation ltx_align_left">(1)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="E1.m1" class="ltx_Math" alttext="\displaystyle{\gamma^{\star}}\triangleq\arg\max_{{\gamma}\in\Gamma}f_{%
\boldsymbol{\gamma}|\boldsymbol{h}}(\gamma|h)" display="inline"><semantics><mrow><msup><mi>Î³</mi><mo>â‹†</mo></msup><mo>â‰œ</mo><mrow><mrow><mi>arg</mi><mo lspace="0.167em">â¡</mo><mrow><munder><mi>max</mi><mrow><mi>Î³</mi><mo>âˆˆ</mo><mi mathvariant="normal">Î“</mi></mrow></munder><mo lspace="0.167em">â¡</mo><msub><mi>f</mi><mrow><mi>ğœ¸</mi><mo fence="false">|</mo><mi>ğ’‰</mi></mrow></msub></mrow></mrow><mo>â¢</mo><mrow><mo stretchy="false">(</mo><mrow><mi>Î³</mi><mo fence="false">|</mo><mi>h</mi></mrow><mo stretchy="false">)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">\displaystyle{\gamma^{\star}}\triangleq\arg\max_{{\gamma}\in\Gamma}f_{%
\boldsymbol{\gamma}|\boldsymbol{h}}(\gamma|h)</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<p class="ltx_p">The conditional distribution <math id="p2.m5" class="ltx_Math" alttext="f_{\boldsymbol{\gamma}|\boldsymbol{h}}(\gamma|h)" display="inline"><semantics><mrow><msub><mi>f</mi><mrow><mi>ğœ¸</mi><mo fence="false">|</mo><mi>ğ’‰</mi></mrow></msub><mo>â¢</mo><mrow><mo stretchy="false">(</mo><mrow><mi>Î³</mi><mo fence="false">|</mo><mi>h</mi></mrow><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">f_{\boldsymbol{\gamma}|\boldsymbol{h}}(\gamma|h)</annotation></semantics></math> is frequently referred to as the <em class="ltx_emph ltx_font_italic">posterior distribution</em> of <math id="p2.m6" class="ltx_Math" alttext="\boldsymbol{\gamma}" display="inline"><semantics><mi>ğœ¸</mi><annotation encoding="application/x-tex">\boldsymbol{\gamma}</annotation></semantics></math>, making <math id="p2.m7" class="ltx_Math" alttext="{\gamma^{\star}}" display="inline"><semantics><msup><mi>Î³</mi><mo>â‹†</mo></msup><annotation encoding="application/x-tex">{\gamma^{\star}}</annotation></semantics></math> the <em class="ltx_emph ltx_font_italic">maximum a posteriori (MAP) estimate</em> of <math id="p2.m8" class="ltx_Math" alttext="\boldsymbol{\gamma}" display="inline"><semantics><mi>ğœ¸</mi><annotation encoding="application/x-tex">\boldsymbol{\gamma}</annotation></semantics></math> given <math id="p2.m9" class="ltx_Math" alttext="\boldsymbol{h}" display="inline"><semantics><mi>ğ’‰</mi><annotation encoding="application/x-tex">\boldsymbol{h}</annotation></semantics></math>. We note that it is common in the literature on estimation theory to the employ hat-notation to refer to estimates of a random quantity based on data. In this sense, we could have opted to denote the optimal solution toÂ (<a href="#E1" title="In 1. BAYESIAN INFERENCE â€£ Lecture 1: Foundations in Deterministic and Stochastic Optimization" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>) by <math id="p2.m10" class="ltx_Math" alttext="\widehat{\gamma}" display="inline"><semantics><mover accent="true"><mi>Î³</mi><mo>^</mo></mover><annotation encoding="application/x-tex">\widehat{\gamma}</annotation></semantics></math>, rather than <math id="p2.m11" class="ltx_Math" alttext="\gamma^{\star}" display="inline"><semantics><msup><mi>Î³</mi><mo>â‹†</mo></msup><annotation encoding="application/x-tex">\gamma^{\star}</annotation></semantics></math>. Nevertheless, as we transition from inference to learning and optimization, we will increasingly interpret estimates as solutions to generic optimization problems. In this context, it will be appropriate to employ the <sup class="ltx_sup"><span class="ltx_text ltx_font_italic">â‹†</span></sup>-notation to refer to an optimal solution. To preserve consistency throughout this text, we opt to use the <sup class="ltx_sup"><span class="ltx_text ltx_font_italic">â‹†</span></sup>-notation from the onset, with the understanding that within the Bayesian frameworkÂ (<a href="#E1" title="In 1. BAYESIAN INFERENCE â€£ Lecture 1: Foundations in Deterministic and Stochastic Optimization" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>) the optimal solution <math id="p2.m14" class="ltx_Math" alttext="\gamma^{\star}" display="inline"><semantics><msup><mi>Î³</mi><mo>â‹†</mo></msup><annotation encoding="application/x-tex">\gamma^{\star}</annotation></semantics></math> carries the interpretation of an estimate. Finally, we note thatÂ (<a href="#E1" title="In 1. BAYESIAN INFERENCE â€£ Lecture 1: Foundations in Deterministic and Stochastic Optimization" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>) is formulated for a particular realization <math id="p2.m15" class="ltx_Math" alttext="h" display="inline"><semantics><mi>h</mi><annotation encoding="application/x-tex">h</annotation></semantics></math> of the random variable <math id="p2.m16" class="ltx_Math" alttext="\boldsymbol{h}" display="inline"><semantics><mi>ğ’‰</mi><annotation encoding="application/x-tex">\boldsymbol{h}</annotation></semantics></math>. As we will see, most MAP estimators are derived for a particular realization of the feature vector, resulting in a deterministic estimate <math id="p2.m17" class="ltx_Math" alttext="\gamma^{\star}" display="inline"><semantics><msup><mi>Î³</mi><mo>â‹†</mo></msup><annotation encoding="application/x-tex">\gamma^{\star}</annotation></semantics></math> as a function of the realization <math id="p2.m18" class="ltx_Math" alttext="h" display="inline"><semantics><mi>h</mi><annotation encoding="application/x-tex">h</annotation></semantics></math>. We can also regard the MAP solution as a random variable, denoted in boldface notation <math id="p2.m19" class="ltx_Math" alttext="\boldsymbol{\gamma}^{\star}" display="inline"><semantics><msup><mi>ğœ¸</mi><mo>â‹†</mo></msup><annotation encoding="application/x-tex">\boldsymbol{\gamma}^{\star}</annotation></semantics></math>, when it is viewed as a function of the random observation <math id="p2.m20" class="ltx_Math" alttext="{\boldsymbol{h}}" display="inline"><semantics><mi>ğ’‰</mi><annotation encoding="application/x-tex">{\boldsymbol{h}}</annotation></semantics></math>:</p>
<div style="max-width: 100%; overflow-x: auto; overflow-y: hidden;">
<table id="S2.EGx2" class="ltx_equationgroup ltx_eqn_align ltx_eqn_table">

<tbody id="E2"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left"><span class="ltx_tag ltx_tag_equation ltx_align_left">(2)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="E2.m1" class="ltx_Math" alttext="\displaystyle\boldsymbol{\gamma}^{\star}\triangleq\arg\max_{{\gamma}\in\Gamma}%
f_{\boldsymbol{\gamma}|\boldsymbol{h}}(\gamma|\boldsymbol{h})" display="inline"><semantics><mrow><msup><mi>ğœ¸</mi><mo>â‹†</mo></msup><mo>â‰œ</mo><mrow><mrow><mi>arg</mi><mo lspace="0.167em">â¡</mo><mrow><munder><mi>max</mi><mrow><mi>Î³</mi><mo>âˆˆ</mo><mi mathvariant="normal">Î“</mi></mrow></munder><mo lspace="0.167em">â¡</mo><msub><mi>f</mi><mrow><mi>ğœ¸</mi><mo fence="false">|</mo><mi>ğ’‰</mi></mrow></msub></mrow></mrow><mo>â¢</mo><mrow><mo stretchy="false">(</mo><mrow><mi>Î³</mi><mo fence="false">|</mo><mi>ğ’‰</mi></mrow><mo stretchy="false">)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">\displaystyle\boldsymbol{\gamma}^{\star}\triangleq\arg\max_{{\gamma}\in\Gamma}%
f_{\boldsymbol{\gamma}|\boldsymbol{h}}(\gamma|\boldsymbol{h})</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<p class="ltx_p">where the posterior distribution <math id="p2.m21" class="ltx_Math" alttext="f_{\boldsymbol{\gamma}|\boldsymbol{h}}(\gamma|\boldsymbol{h})" display="inline"><semantics><mrow><msub><mi>f</mi><mrow><mi>ğœ¸</mi><mo fence="false">|</mo><mi>ğ’‰</mi></mrow></msub><mo>â¢</mo><mrow><mo stretchy="false">(</mo><mrow><mi>Î³</mi><mo fence="false">|</mo><mi>ğ’‰</mi></mrow><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">f_{\boldsymbol{\gamma}|\boldsymbol{h}}(\gamma|\boldsymbol{h})</annotation></semantics></math> is now a function of the random variable <math id="p2.m22" class="ltx_Math" alttext="\boldsymbol{h}" display="inline"><semantics><mi>ğ’‰</mi><annotation encoding="application/x-tex">\boldsymbol{h}</annotation></semantics></math>, rather than its realization <math id="p2.m23" class="ltx_Math" alttext="h" display="inline"><semantics><mi>h</mi><annotation encoding="application/x-tex">h</annotation></semantics></math>.</p>
</div>
<div id="Thmremark1" class="ltx_theorem ltx_theorem_remark">

<h6 class="ltx_title ltx_runin ltx_title_theorem">
<span class="ltx_tag ltx_tag_theorem header-section-number"><span class="ltx_text ltx_font_italic">Remark 1.1</span></span><span class="ltx_text ltx_font_italic"> </span>(<span class="ltx_text ltx_font_bold"> Bold font indicates random variables</span>)<span class="ltx_text ltx_font_italic">.</span>
</h6>
<div id="Thmremark1.p1" class="ltx_para">
<p class="ltx_p">We note that we employ bold font to denote a random variables, for example <math id="Thmremark1.p1.m1" class="ltx_Math" alttext="\boldsymbol{h}" display="inline"><semantics><mi>ğ’‰</mi><annotation encoding="application/x-tex">\boldsymbol{h}</annotation></semantics></math>, while regular font denotes its realization or a deterministic quanity, as in <math id="Thmremark1.p1.m2" class="ltx_Math" alttext="h" display="inline"><semantics><mi>h</mi><annotation encoding="application/x-tex">h</annotation></semantics></math>. As a general rule, we use lowercase fonts to denote vectors, while uppercase letters denote matrices. In this way, a random matrix would be denoted by <math id="Thmremark1.p1.m3" class="ltx_Math" alttext="\boldsymbol{H}" display="inline"><semantics><mi>ğ‘¯</mi><annotation encoding="application/x-tex">\boldsymbol{H}</annotation></semantics></math>, while its realization would correspond to <math id="Thmremark1.p1.m4" class="ltx_Math" alttext="H" display="inline"><semantics><mi>H</mi><annotation encoding="application/x-tex">H</annotation></semantics></math>.</p>
</div>
</div>
<figure id="F1" class="ltx_figure"><div style="max-width: 100%; overflow-x: auto; overflow-y: hidden;"><img src="" id="F1.g1" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" alt="Refer to caption"></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1. </span><span class="ltx_text" style="font-size:90%;">A general model underlying most inference problems. The top row illustrates the generative model for the observations <math id="F1.m2" class="ltx_Math" alttext="{\boldsymbol{h}}" display="inline"><semantics><mi>ğ’‰</mi><annotation encoding="application/x-tex">{\boldsymbol{h}}</annotation></semantics></math>, while the bottom row illustrates the Bayesian inference formulation for recovering the label variable.</span></figcaption>
</figure>
</div>
</section>
</div>
</div>
</div>
<a href="index.html" class="navigation navigation-prev" aria-label="Previous page"><i class="fa fa-angle-left"></i></a><a href="S2.html" class="navigation navigation-next" aria-label="Next page"><i class="fa fa-angle-right"></i></a>
</div>
</div>
<script src="bookml/gitbook/js/app.min.js"></script>
<script src="bookml/gitbook/js/plugin-fontsettings.js"></script>
<script src="bookml/gitbook/js/plugin-bookdown.js"></script>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script>
        MathJax = {
          startup: {
            ready() {
              // do not process equations disabled with \bmlDisableMathJax (code suggested by Davide P. Cervone)
              class bmlFindMathML extends MathJax._.input.mathml.FindMathML.FindMathML {
                processMath(set) {
                  const adaptor = this.adaptor;
                  for (const node of set.values()) {
                    if (adaptor.hasClass(node, 'bml_disable_mathjax')) {
                      set.delete(node);
                    }
                  }
                  return super.processMath(set);
                }
              }

              MathJax._.components.global.combineDefaults(MathJax.config, 'mml', {FindMathML: new bmlFindMathML()});

              MathJax.startup.defaultReady();

              // preproces MathML to make MathJax aware of certain LaTeXML and BookML additional info
              const mmlFilters = MathJax.startup.input[0].mmlFilters;

              // convert the LaTeXML calligraphic (chancery) annotation to a form MathJax understands
              // since the corresponding Unicode characters render as script (rounded)
              const script2latin = {
                'ğ’œ': 'A', 'â„¬': 'B', 'ğ’': 'C', 'ğ’Ÿ': 'D', 'â„°': 'E', 'â„±': 'F', 'ğ’¢': 'G',
                'â„‹': 'H', 'â„': 'I', 'ğ’¥': 'J', 'ğ’¦': 'K', 'â„’': 'L', 'â„³': 'M', 'ğ’©': 'N',
                'ğ’ª': 'O', 'ğ’«': 'P', 'ğ’¬': 'Q', 'â„›': 'R', 'ğ’®': 'S', 'ğ’¯': 'T', 'ğ’°': 'U',
                'ğ’±': 'V', 'ğ’²': 'W', 'ğ’³': 'X', 'ğ’´': 'Y', 'ğ’µ': 'Z',
              };

              mmlFilters.add((args) => {
                for (const n of args.data.getElementsByClassName('ltx_font_mathcaligraphic')) {
                  n.classList.add('MJX-tex-calligraphic');
                  const letter = script2latin[n.textContent];
                  if (letter !== undefined) { n.textContent = letter; }
                }
              });

              // adjust characters based on Unicode variation sequences
              const replacements = {
                // MathJax renders the empty set as the U+FE00 variant, so the plain character needs adjusting
                'âˆ…': { variant: 'variant' },
                // MathJax renders script characters in rounded style, which is fine for no variation and U+FE00
                'ğ’œ\xFE00': { text: 'A', variant: 'tex-calligraphic' },
                'â„¬\xFE00': { text: 'B', variant: 'tex-calligraphic' },
                'ğ’\xFE00': { text: 'C', variant: 'tex-calligraphic' },
                'ğ’Ÿ\xFE00': { text: 'D', variant: 'tex-calligraphic' },
                'â„°\xFE00': { text: 'E', variant: 'tex-calligraphic' },
                'â„±\xFE00': { text: 'F', variant: 'tex-calligraphic' },
                'ğ’¢\xFE00': { text: 'G', variant: 'tex-calligraphic' },
                'â„‹\xFE00': { text: 'H', variant: 'tex-calligraphic' },
                'â„\xFE00': { text: 'I', variant: 'tex-calligraphic' },
                'ğ’¥\xFE00': { text: 'J', variant: 'tex-calligraphic' },
                'ğ’¦\xFE00': { text: 'K', variant: 'tex-calligraphic' },
                'â„’\xFE00': { text: 'L', variant: 'tex-calligraphic' },
                'â„³\xFE00': { text: 'M', variant: 'tex-calligraphic' },
                'ğ’©\xFE00': { text: 'N', variant: 'tex-calligraphic' },
                'ğ’ª\xFE00': { text: 'O', variant: 'tex-calligraphic' },
                'ğ’«\xFE00': { text: 'P', variant: 'tex-calligraphic' },
                'ğ’¬\xFE00': { text: 'Q', variant: 'tex-calligraphic' },
                'â„›\xFE00': { text: 'R', variant: 'tex-calligraphic' },
                'ğ’®\xFE00': { text: 'S', variant: 'tex-calligraphic' },
                'ğ’¯\xFE00': { text: 'T', variant: 'tex-calligraphic' },
                'ğ’°\xFE00': { text: 'U', variant: 'tex-calligraphic' },
                'ğ’±\xFE00': { text: 'V', variant: 'tex-calligraphic' },
                'ğ’²\xFE00': { text: 'W', variant: 'tex-calligraphic' },
                'ğ’³\xFE00': { text: 'X', variant: 'tex-calligraphic' },
                'ğ’´\xFE00': { text: 'Y', variant: 'tex-calligraphic' },
                'ğ’µ\xFE00': { text: 'Z', variant: 'tex-calligraphic' }
              };

              mmlFilters.add((args) => {
                let nodes = document.evaluate('.//m:mi | .//m:mn | .//m:mo | .//m:ms', args.data,
                  () => 'http://www.w3.org/1998/Math/MathML', XPathResult.UNORDERED_NODE_SNAPSHOT_TYPE);
                for (let i = 0; i < nodes.snapshotLength; i++) {
                  const n = nodes.snapshotItem(i);
                  const repl = replacements[n.innerHTML];
                  if (repl !== undefined) {
                    const variant = repl['variant'];
                    const text = repl['text'];
                    if (variant !== undefined) { n.classList.add('MJX-' + variant); n.removeAttribute('mathvariant'); }
                    if (text !== undefined) { n.innerHTML = text; }
                  }
                }
              });
            }
          }
        };
      </script>
<script id="MathJax-script" async="" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/mml-chtml.js"></script>
<script type="text/javascript">
              gitbook.require(["gitbook"], function(gitbook) {
              gitbook.start({
                "fontsettings": {
                  "theme": "white",
                  "family": "sans",
                  "size": 2
                },
                "download": [ [ "lecture1.pdf", "PDF (serif)" ], ],
                  "search": false,
                  "toc": {
                    "collapse": "none"
                  }
                });
              });
            </script>
</body>

</html>
