<!DOCTYPE html><html lang="en-GB">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>1. BAYESIAN INFERENCE ‣ Lecture 1: Foundations in Deterministic and Stochastic Optimization</title>
<!--Generated on Mon Mar 18 14:06:24 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->

<link rel="stylesheet" href="LaTeXML.css" type="text/css">
<link rel="stylesheet" href="ltx-article.css" type="text/css">
<link rel="stylesheet" href="ltx-amsart.css" type="text/css">
<link rel="stylesheet" href="bookml/gitbook/css/style.css" type="text/css">
<link rel="stylesheet" href="bookml/gitbook/css/plugin-table.css" type="text/css">
<link rel="stylesheet" href="bookml/gitbook/css/plugin-bookdown.css" type="text/css">
<link rel="stylesheet" href="bookml/gitbook/css/plugin-fontsettings.css" type="text/css">
<link rel="stylesheet" href="bookml/CSS/style.css" type="text/css">
<link rel="stylesheet" href="bookml/CSS/style.gitbook,plain.css" type="text/css">
<link rel="stylesheet" href="bookml/CSS/style.gitbook.css" type="text/css">
<link rel="stylesheet" href="bmluser/lecture1.colors.gitbook.css" type="text/css">
<link rel="stylesheet" href="bmluser/template.colors.gitbook.css" type="text/css">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<script src="https://code.jquery.com/jquery-3.6.0.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>
<link rel="up" href="index.html" title="Lecture 1: Foundations in Deterministic and Stochastic Optimization">
<link rel="start" href="index.html" title="Lecture 1: Foundations in Deterministic and Stochastic Optimization">
<link rel="prev" href="index.html" title="Lecture 1: Foundations in Deterministic and Stochastic Optimization">
<link rel="next" href="S2.html" title="2. From Inference to Learning ‣ Lecture 1: Foundations in Deterministic and Stochastic Optimization">
<link rel="section" href="S2.html" title="2. From Inference to Learning ‣ Lecture 1: Foundations in Deterministic and Stochastic Optimization">
</head>
<body>
<div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">
<a href="#bml-main-content" tabindex="0" class="bml-skip-to-content">Skip to content.</a>
<div class="book-summary"><nav class="ltx_page_navbar">
<ul class="ltx_toclist summary">
<li>
<a href="index.html" title="" class="ltx_ref" rel="start">Lecture 1: Foundations in Deterministic and Stochastic Optimization</a>
</li>
<li class="divider">
<li data-level="1" data-path="" class="ltx_tocentry ltx_tocentry_section ltx_ref_self  chapter active"><a href="" title="In Lecture 1: Foundations in Deterministic and Stochastic Optimization" class="ltx_ref"><b><span class="ltx_tag ltx_tag_ref">1 </span></b>Bayesian Inference</a></li>
<li data-level="2" data-path="S2.html" class="ltx_tocentry ltx_tocentry_section  chapter "><a href="S2.html" title="In Lecture 1: Foundations in Deterministic and Stochastic Optimization" class="ltx_ref"><b><span class="ltx_tag ltx_tag_ref">2 </span></b>From Inference to Learning</a></li>
</ul>
</nav></div>
<div class="ltx_page_main book-body fixed">
<div class="body-inner">
<div class="book-header fixed" role="navigation"><h1>BAYESIAN INFERENCE</h1></div>
<div class="page-wrapper" tabindex="-1" role="main">
<div class="ltx_page_content page-inner" id="bml-main-content">
<section class="ltx_section ltx_authors_1line ltx_leqno normal" lang="en-GB">
<div class="section level1">

<h1 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section header-section-number">1</span>. BAYESIAN INFERENCE</h1>

<div id="p1" class="ltx_para">
<p class="ltx_p">One of the most fundamental problems in statistics, signal processing, and machine learning, is the <em class="ltx_emph ltx_font_italic">inference</em> problem, where we wish to construct an estimate of some random quantity of interest <math id="p1.m1" class="ltx_Math" alttext="\boldsymbol{\gamma}\in\mathds{R}^{M_{\boldsymbol{\gamma}}}" display="inline"><semantics><mrow><mi>𝜸</mi><mo>∈</mo><msup><mi>ℝ</mi><msub><mi>M</mi><mi>𝜸</mi></msub></msup></mrow><annotation encoding="application/x-tex">\boldsymbol{\gamma}\in\mathds{R}^{M_{\boldsymbol{\gamma}}}</annotation></semantics></math>, given observations of a related random variable <math id="p1.m2" class="ltx_Math" alttext="\boldsymbol{h}\in\mathds{R}^{M_{\boldsymbol{h}}}" display="inline"><semantics><mrow><mi>𝒉</mi><mo>∈</mo><msup><mi>ℝ</mi><msub><mi>M</mi><mi>𝒉</mi></msub></msup></mrow><annotation encoding="application/x-tex">\boldsymbol{h}\in\mathds{R}^{M_{\boldsymbol{h}}}</annotation></semantics></math>. The quantity of interest <math id="p1.m3" class="ltx_Math" alttext="\boldsymbol{\gamma}" display="inline"><semantics><mi>𝜸</mi><annotation encoding="application/x-tex">\boldsymbol{\gamma}</annotation></semantics></math> may take on continuous or discrete values, and is referred to as the “dependent variable,” “state of nature,” “class,” or “label” depending on the application. We will most commonly refer to it as the label. We will refer to the observed random variable <math id="p1.m4" class="ltx_Math" alttext="\boldsymbol{h}" display="inline"><semantics><mi>𝒉</mi><annotation encoding="application/x-tex">\boldsymbol{h}</annotation></semantics></math> generally as the feature, although in some applications it is known as “regressor” or “observation”.</p>
</div>
<div id="p2" class="ltx_para">
<p class="ltx_p">If we are provided with the conditional distribution <math id="p2.m1" class="ltx_Math" alttext="f_{\boldsymbol{\gamma}|\boldsymbol{h}}(\gamma|h)" display="inline"><semantics><mrow><msub><mi>f</mi><mrow><mi>𝜸</mi><mo fence="false">|</mo><mi>𝒉</mi></mrow></msub><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mrow><mi>γ</mi><mo fence="false">|</mo><mi>h</mi></mrow><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">f_{\boldsymbol{\gamma}|\boldsymbol{h}}(\gamma|h)</annotation></semantics></math> along with a single realization of the feature <math id="p2.m2" class="ltx_Math" alttext="\boldsymbol{h}" display="inline"><semantics><mi>𝒉</mi><annotation encoding="application/x-tex">\boldsymbol{h}</annotation></semantics></math>, it is quite natural to estimate <math id="p2.m3" class="ltx_Math" alttext="\boldsymbol{\gamma}" display="inline"><semantics><mi>𝜸</mi><annotation encoding="application/x-tex">\boldsymbol{\gamma}</annotation></semantics></math> as the most likely outcome given <math id="p2.m4" class="ltx_Math" alttext="\boldsymbol{h}" display="inline"><semantics><mi>𝒉</mi><annotation encoding="application/x-tex">\boldsymbol{h}</annotation></semantics></math>. We can express this formally as:</p>
<div style="max-width: 100%; overflow-x: auto; overflow-y: hidden;">
<table id="S2.EGx1" class="ltx_equationgroup ltx_eqn_align ltx_eqn_table">

<tbody id="E1"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left"><span class="ltx_tag ltx_tag_equation ltx_align_left">(1)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="E1.m1" class="ltx_Math" alttext="\displaystyle{\gamma^{\star}}\triangleq\arg\max_{{\gamma}\in\Gamma}f_{%
\boldsymbol{\gamma}|\boldsymbol{h}}(\gamma|h)" display="inline"><semantics><mrow><msup><mi>γ</mi><mo>⋆</mo></msup><mo>≜</mo><mrow><mrow><mi>arg</mi><mo lspace="0.167em">⁡</mo><mrow><munder><mi>max</mi><mrow><mi>γ</mi><mo>∈</mo><mi mathvariant="normal">Γ</mi></mrow></munder><mo lspace="0.167em">⁡</mo><msub><mi>f</mi><mrow><mi>𝜸</mi><mo fence="false">|</mo><mi>𝒉</mi></mrow></msub></mrow></mrow><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mrow><mi>γ</mi><mo fence="false">|</mo><mi>h</mi></mrow><mo stretchy="false">)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">\displaystyle{\gamma^{\star}}\triangleq\arg\max_{{\gamma}\in\Gamma}f_{%
\boldsymbol{\gamma}|\boldsymbol{h}}(\gamma|h)</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<p class="ltx_p">The conditional distribution <math id="p2.m5" class="ltx_Math" alttext="f_{\boldsymbol{\gamma}|\boldsymbol{h}}(\gamma|h)" display="inline"><semantics><mrow><msub><mi>f</mi><mrow><mi>𝜸</mi><mo fence="false">|</mo><mi>𝒉</mi></mrow></msub><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mrow><mi>γ</mi><mo fence="false">|</mo><mi>h</mi></mrow><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">f_{\boldsymbol{\gamma}|\boldsymbol{h}}(\gamma|h)</annotation></semantics></math> is frequently referred to as the <em class="ltx_emph ltx_font_italic">posterior distribution</em> of <math id="p2.m6" class="ltx_Math" alttext="\boldsymbol{\gamma}" display="inline"><semantics><mi>𝜸</mi><annotation encoding="application/x-tex">\boldsymbol{\gamma}</annotation></semantics></math>, making <math id="p2.m7" class="ltx_Math" alttext="{\gamma^{\star}}" display="inline"><semantics><msup><mi>γ</mi><mo>⋆</mo></msup><annotation encoding="application/x-tex">{\gamma^{\star}}</annotation></semantics></math> the <em class="ltx_emph ltx_font_italic">maximum a posteriori (MAP) estimate</em> of <math id="p2.m8" class="ltx_Math" alttext="\boldsymbol{\gamma}" display="inline"><semantics><mi>𝜸</mi><annotation encoding="application/x-tex">\boldsymbol{\gamma}</annotation></semantics></math> given <math id="p2.m9" class="ltx_Math" alttext="\boldsymbol{h}" display="inline"><semantics><mi>𝒉</mi><annotation encoding="application/x-tex">\boldsymbol{h}</annotation></semantics></math>. We note that it is common in the literature on estimation theory to the employ hat-notation to refer to estimates of a random quantity based on data. In this sense, we could have opted to denote the optimal solution to (<a href="#E1" title="In 1. BAYESIAN INFERENCE ‣ Lecture 1: Foundations in Deterministic and Stochastic Optimization" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>) by <math id="p2.m10" class="ltx_Math" alttext="\widehat{\gamma}" display="inline"><semantics><mover accent="true"><mi>γ</mi><mo>^</mo></mover><annotation encoding="application/x-tex">\widehat{\gamma}</annotation></semantics></math>, rather than <math id="p2.m11" class="ltx_Math" alttext="\gamma^{\star}" display="inline"><semantics><msup><mi>γ</mi><mo>⋆</mo></msup><annotation encoding="application/x-tex">\gamma^{\star}</annotation></semantics></math>. Nevertheless, as we transition from inference to learning and optimization, we will increasingly interpret estimates as solutions to generic optimization problems. In this context, it will be appropriate to employ the <sup class="ltx_sup"><span class="ltx_text ltx_font_italic">⋆</span></sup>-notation to refer to an optimal solution. To preserve consistency throughout this text, we opt to use the <sup class="ltx_sup"><span class="ltx_text ltx_font_italic">⋆</span></sup>-notation from the onset, with the understanding that within the Bayesian framework (<a href="#E1" title="In 1. BAYESIAN INFERENCE ‣ Lecture 1: Foundations in Deterministic and Stochastic Optimization" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>) the optimal solution <math id="p2.m14" class="ltx_Math" alttext="\gamma^{\star}" display="inline"><semantics><msup><mi>γ</mi><mo>⋆</mo></msup><annotation encoding="application/x-tex">\gamma^{\star}</annotation></semantics></math> carries the interpretation of an estimate. Finally, we note that (<a href="#E1" title="In 1. BAYESIAN INFERENCE ‣ Lecture 1: Foundations in Deterministic and Stochastic Optimization" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>) is formulated for a particular realization <math id="p2.m15" class="ltx_Math" alttext="h" display="inline"><semantics><mi>h</mi><annotation encoding="application/x-tex">h</annotation></semantics></math> of the random variable <math id="p2.m16" class="ltx_Math" alttext="\boldsymbol{h}" display="inline"><semantics><mi>𝒉</mi><annotation encoding="application/x-tex">\boldsymbol{h}</annotation></semantics></math>. As we will see, most MAP estimators are derived for a particular realization of the feature vector, resulting in a deterministic estimate <math id="p2.m17" class="ltx_Math" alttext="\gamma^{\star}" display="inline"><semantics><msup><mi>γ</mi><mo>⋆</mo></msup><annotation encoding="application/x-tex">\gamma^{\star}</annotation></semantics></math> as a function of the realization <math id="p2.m18" class="ltx_Math" alttext="h" display="inline"><semantics><mi>h</mi><annotation encoding="application/x-tex">h</annotation></semantics></math>. We can also regard the MAP solution as a random variable, denoted in boldface notation <math id="p2.m19" class="ltx_Math" alttext="\boldsymbol{\gamma}^{\star}" display="inline"><semantics><msup><mi>𝜸</mi><mo>⋆</mo></msup><annotation encoding="application/x-tex">\boldsymbol{\gamma}^{\star}</annotation></semantics></math>, when it is viewed as a function of the random observation <math id="p2.m20" class="ltx_Math" alttext="{\boldsymbol{h}}" display="inline"><semantics><mi>𝒉</mi><annotation encoding="application/x-tex">{\boldsymbol{h}}</annotation></semantics></math>:</p>
<div style="max-width: 100%; overflow-x: auto; overflow-y: hidden;">
<table id="S2.EGx2" class="ltx_equationgroup ltx_eqn_align ltx_eqn_table">

<tbody id="E2"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left"><span class="ltx_tag ltx_tag_equation ltx_align_left">(2)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="E2.m1" class="ltx_Math" alttext="\displaystyle\boldsymbol{\gamma}^{\star}\triangleq\arg\max_{{\gamma}\in\Gamma}%
f_{\boldsymbol{\gamma}|\boldsymbol{h}}(\gamma|\boldsymbol{h})" display="inline"><semantics><mrow><msup><mi>𝜸</mi><mo>⋆</mo></msup><mo>≜</mo><mrow><mrow><mi>arg</mi><mo lspace="0.167em">⁡</mo><mrow><munder><mi>max</mi><mrow><mi>γ</mi><mo>∈</mo><mi mathvariant="normal">Γ</mi></mrow></munder><mo lspace="0.167em">⁡</mo><msub><mi>f</mi><mrow><mi>𝜸</mi><mo fence="false">|</mo><mi>𝒉</mi></mrow></msub></mrow></mrow><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mrow><mi>γ</mi><mo fence="false">|</mo><mi>𝒉</mi></mrow><mo stretchy="false">)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">\displaystyle\boldsymbol{\gamma}^{\star}\triangleq\arg\max_{{\gamma}\in\Gamma}%
f_{\boldsymbol{\gamma}|\boldsymbol{h}}(\gamma|\boldsymbol{h})</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<p class="ltx_p">where the posterior distribution <math id="p2.m21" class="ltx_Math" alttext="f_{\boldsymbol{\gamma}|\boldsymbol{h}}(\gamma|\boldsymbol{h})" display="inline"><semantics><mrow><msub><mi>f</mi><mrow><mi>𝜸</mi><mo fence="false">|</mo><mi>𝒉</mi></mrow></msub><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mrow><mi>γ</mi><mo fence="false">|</mo><mi>𝒉</mi></mrow><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">f_{\boldsymbol{\gamma}|\boldsymbol{h}}(\gamma|\boldsymbol{h})</annotation></semantics></math> is now a function of the random variable <math id="p2.m22" class="ltx_Math" alttext="\boldsymbol{h}" display="inline"><semantics><mi>𝒉</mi><annotation encoding="application/x-tex">\boldsymbol{h}</annotation></semantics></math>, rather than its realization <math id="p2.m23" class="ltx_Math" alttext="h" display="inline"><semantics><mi>h</mi><annotation encoding="application/x-tex">h</annotation></semantics></math>.</p>
</div>
<div id="Thmremark1" class="ltx_theorem ltx_theorem_remark">

<h6 class="ltx_title ltx_runin ltx_title_theorem">
<span class="ltx_tag ltx_tag_theorem header-section-number"><span class="ltx_text ltx_font_italic">Remark 1.1</span></span><span class="ltx_text ltx_font_italic"> </span>(<span class="ltx_text ltx_font_bold"> Bold font indicates random variables</span>)<span class="ltx_text ltx_font_italic">.</span>
</h6>
<div id="Thmremark1.p1" class="ltx_para">
<p class="ltx_p">We note that we employ bold font to denote a random variables, for example <math id="Thmremark1.p1.m1" class="ltx_Math" alttext="\boldsymbol{h}" display="inline"><semantics><mi>𝒉</mi><annotation encoding="application/x-tex">\boldsymbol{h}</annotation></semantics></math>, while regular font denotes its realization or a deterministic quanity, as in <math id="Thmremark1.p1.m2" class="ltx_Math" alttext="h" display="inline"><semantics><mi>h</mi><annotation encoding="application/x-tex">h</annotation></semantics></math>. As a general rule, we use lowercase fonts to denote vectors, while uppercase letters denote matrices. In this way, a random matrix would be denoted by <math id="Thmremark1.p1.m3" class="ltx_Math" alttext="\boldsymbol{H}" display="inline"><semantics><mi>𝑯</mi><annotation encoding="application/x-tex">\boldsymbol{H}</annotation></semantics></math>, while its realization would correspond to <math id="Thmremark1.p1.m4" class="ltx_Math" alttext="H" display="inline"><semantics><mi>H</mi><annotation encoding="application/x-tex">H</annotation></semantics></math>.</p>
</div>
</div>
<figure id="F1" class="ltx_figure"><div style="max-width: 100%; overflow-x: auto; overflow-y: hidden;"><img src="" id="F1.g1" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" alt="Refer to caption"></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1. </span><span class="ltx_text" style="font-size:90%;">A general model underlying most inference problems. The top row illustrates the generative model for the observations <math id="F1.m2" class="ltx_Math" alttext="{\boldsymbol{h}}" display="inline"><semantics><mi>𝒉</mi><annotation encoding="application/x-tex">{\boldsymbol{h}}</annotation></semantics></math>, while the bottom row illustrates the Bayesian inference formulation for recovering the label variable.</span></figcaption>
</figure>
</div>
</section>
</div>
</div>
</div>
<a href="index.html" class="navigation navigation-prev" aria-label="Previous page"><i class="fa fa-angle-left"></i></a><a href="S2.html" class="navigation navigation-next" aria-label="Next page"><i class="fa fa-angle-right"></i></a>
</div>
</div>
<script src="bookml/gitbook/js/app.min.js"></script>
<script src="bookml/gitbook/js/plugin-fontsettings.js"></script>
<script src="bookml/gitbook/js/plugin-bookdown.js"></script>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script>
        MathJax = {
          startup: {
            ready() {
              // do not process equations disabled with \bmlDisableMathJax (code suggested by Davide P. Cervone)
              class bmlFindMathML extends MathJax._.input.mathml.FindMathML.FindMathML {
                processMath(set) {
                  const adaptor = this.adaptor;
                  for (const node of set.values()) {
                    if (adaptor.hasClass(node, 'bml_disable_mathjax')) {
                      set.delete(node);
                    }
                  }
                  return super.processMath(set);
                }
              }

              MathJax._.components.global.combineDefaults(MathJax.config, 'mml', {FindMathML: new bmlFindMathML()});

              MathJax.startup.defaultReady();

              // preproces MathML to make MathJax aware of certain LaTeXML and BookML additional info
              const mmlFilters = MathJax.startup.input[0].mmlFilters;

              // convert the LaTeXML calligraphic (chancery) annotation to a form MathJax understands
              // since the corresponding Unicode characters render as script (rounded)
              const script2latin = {
                '𝒜': 'A', 'ℬ': 'B', '𝒞': 'C', '𝒟': 'D', 'ℰ': 'E', 'ℱ': 'F', '𝒢': 'G',
                'ℋ': 'H', 'ℐ': 'I', '𝒥': 'J', '𝒦': 'K', 'ℒ': 'L', 'ℳ': 'M', '𝒩': 'N',
                '𝒪': 'O', '𝒫': 'P', '𝒬': 'Q', 'ℛ': 'R', '𝒮': 'S', '𝒯': 'T', '𝒰': 'U',
                '𝒱': 'V', '𝒲': 'W', '𝒳': 'X', '𝒴': 'Y', '𝒵': 'Z',
              };

              mmlFilters.add((args) => {
                for (const n of args.data.getElementsByClassName('ltx_font_mathcaligraphic')) {
                  n.classList.add('MJX-tex-calligraphic');
                  const letter = script2latin[n.textContent];
                  if (letter !== undefined) { n.textContent = letter; }
                }
              });

              // adjust characters based on Unicode variation sequences
              const replacements = {
                // MathJax renders the empty set as the U+FE00 variant, so the plain character needs adjusting
                '∅': { variant: 'variant' },
                // MathJax renders script characters in rounded style, which is fine for no variation and U+FE00
                '𝒜\xFE00': { text: 'A', variant: 'tex-calligraphic' },
                'ℬ\xFE00': { text: 'B', variant: 'tex-calligraphic' },
                '𝒞\xFE00': { text: 'C', variant: 'tex-calligraphic' },
                '𝒟\xFE00': { text: 'D', variant: 'tex-calligraphic' },
                'ℰ\xFE00': { text: 'E', variant: 'tex-calligraphic' },
                'ℱ\xFE00': { text: 'F', variant: 'tex-calligraphic' },
                '𝒢\xFE00': { text: 'G', variant: 'tex-calligraphic' },
                'ℋ\xFE00': { text: 'H', variant: 'tex-calligraphic' },
                'ℐ\xFE00': { text: 'I', variant: 'tex-calligraphic' },
                '𝒥\xFE00': { text: 'J', variant: 'tex-calligraphic' },
                '𝒦\xFE00': { text: 'K', variant: 'tex-calligraphic' },
                'ℒ\xFE00': { text: 'L', variant: 'tex-calligraphic' },
                'ℳ\xFE00': { text: 'M', variant: 'tex-calligraphic' },
                '𝒩\xFE00': { text: 'N', variant: 'tex-calligraphic' },
                '𝒪\xFE00': { text: 'O', variant: 'tex-calligraphic' },
                '𝒫\xFE00': { text: 'P', variant: 'tex-calligraphic' },
                '𝒬\xFE00': { text: 'Q', variant: 'tex-calligraphic' },
                'ℛ\xFE00': { text: 'R', variant: 'tex-calligraphic' },
                '𝒮\xFE00': { text: 'S', variant: 'tex-calligraphic' },
                '𝒯\xFE00': { text: 'T', variant: 'tex-calligraphic' },
                '𝒰\xFE00': { text: 'U', variant: 'tex-calligraphic' },
                '𝒱\xFE00': { text: 'V', variant: 'tex-calligraphic' },
                '𝒲\xFE00': { text: 'W', variant: 'tex-calligraphic' },
                '𝒳\xFE00': { text: 'X', variant: 'tex-calligraphic' },
                '𝒴\xFE00': { text: 'Y', variant: 'tex-calligraphic' },
                '𝒵\xFE00': { text: 'Z', variant: 'tex-calligraphic' }
              };

              mmlFilters.add((args) => {
                let nodes = document.evaluate('.//m:mi | .//m:mn | .//m:mo | .//m:ms', args.data,
                  () => 'http://www.w3.org/1998/Math/MathML', XPathResult.UNORDERED_NODE_SNAPSHOT_TYPE);
                for (let i = 0; i < nodes.snapshotLength; i++) {
                  const n = nodes.snapshotItem(i);
                  const repl = replacements[n.innerHTML];
                  if (repl !== undefined) {
                    const variant = repl['variant'];
                    const text = repl['text'];
                    if (variant !== undefined) { n.classList.add('MJX-' + variant); n.removeAttribute('mathvariant'); }
                    if (text !== undefined) { n.innerHTML = text; }
                  }
                }
              });
            }
          }
        };
      </script>
<script id="MathJax-script" async="" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/mml-chtml.js"></script>
<script type="text/javascript">
              gitbook.require(["gitbook"], function(gitbook) {
              gitbook.start({
                "fontsettings": {
                  "theme": "white",
                  "family": "sans",
                  "size": 2
                },
                "download": [ [ "lecture1.pdf", "PDF (serif)" ], ],
                  "search": false,
                  "toc": {
                    "collapse": "none"
                  }
                });
              });
            </script>
</body>

</html>
